{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "131a7ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                           f1_score, roc_auc_score, average_precision_score,\n",
    "                           classification_report, confusion_matrix)\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b155f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0f10007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2150cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 103121 entries, 0 to 103120\n",
      "Data columns (total 79 columns):\n",
      " #   Column                      Non-Null Count   Dtype   \n",
      "---  ------                      --------------   -----   \n",
      " 0   Protocol                    103121 non-null  int8    \n",
      " 1   Flow Duration               103121 non-null  int32   \n",
      " 2   Total Fwd Packet            103121 non-null  int32   \n",
      " 3   Total Bwd packets           103121 non-null  int32   \n",
      " 4   Total Length of Fwd Packet  103121 non-null  int32   \n",
      " 5   Total Length of Bwd Packet  103121 non-null  int32   \n",
      " 6   Fwd Packet Length Max       103121 non-null  int32   \n",
      " 7   Fwd Packet Length Min       103121 non-null  int16   \n",
      " 8   Fwd Packet Length Mean      103121 non-null  float32 \n",
      " 9   Fwd Packet Length Std       103121 non-null  float32 \n",
      " 10  Bwd Packet Length Max       103121 non-null  int32   \n",
      " 11  Bwd Packet Length Min       103121 non-null  int16   \n",
      " 12  Bwd Packet Length Mean      103121 non-null  float32 \n",
      " 13  Bwd Packet Length Std       103121 non-null  float32 \n",
      " 14  Flow Bytes/s                103121 non-null  float64 \n",
      " 15  Flow Packets/s              103121 non-null  float64 \n",
      " 16  Flow IAT Mean               103121 non-null  float32 \n",
      " 17  Flow IAT Std                103121 non-null  float32 \n",
      " 18  Flow IAT Max                103121 non-null  int32   \n",
      " 19  Flow IAT Min                103121 non-null  int32   \n",
      " 20  Fwd IAT Total               103121 non-null  int32   \n",
      " 21  Fwd IAT Mean                103121 non-null  float32 \n",
      " 22  Fwd IAT Std                 103121 non-null  float32 \n",
      " 23  Fwd IAT Max                 103121 non-null  int32   \n",
      " 24  Fwd IAT Min                 103121 non-null  int32   \n",
      " 25  Bwd IAT Total               103121 non-null  int32   \n",
      " 26  Bwd IAT Mean                103121 non-null  float32 \n",
      " 27  Bwd IAT Std                 103121 non-null  float32 \n",
      " 28  Bwd IAT Max                 103121 non-null  int32   \n",
      " 29  Bwd IAT Min                 103121 non-null  int32   \n",
      " 30  Fwd PSH Flags               103121 non-null  int8    \n",
      " 31  Bwd PSH Flags               103121 non-null  int8    \n",
      " 32  Fwd URG Flags               103121 non-null  int8    \n",
      " 33  Bwd URG Flags               103121 non-null  int8    \n",
      " 34  Fwd Header Length           103121 non-null  int32   \n",
      " 35  Bwd Header Length           103121 non-null  int32   \n",
      " 36  Fwd Packets/s               103121 non-null  float32 \n",
      " 37  Bwd Packets/s               103121 non-null  float32 \n",
      " 38  Packet Length Min           103121 non-null  int16   \n",
      " 39  Packet Length Max           103121 non-null  int32   \n",
      " 40  Packet Length Mean          103121 non-null  float32 \n",
      " 41  Packet Length Std           103121 non-null  float32 \n",
      " 42  Packet Length Variance      103121 non-null  float32 \n",
      " 43  FIN Flag Count              103121 non-null  int8    \n",
      " 44  SYN Flag Count              103121 non-null  int8    \n",
      " 45  RST Flag Count              103121 non-null  int8    \n",
      " 46  PSH Flag Count              103121 non-null  int32   \n",
      " 47  ACK Flag Count              103121 non-null  int32   \n",
      " 48  URG Flag Count              103121 non-null  int8    \n",
      " 49  CWE Flag Count              103121 non-null  int8    \n",
      " 50  ECE Flag Count              103121 non-null  int8    \n",
      " 51  Down/Up Ratio               103121 non-null  int16   \n",
      " 52  Avg Packet Size             103121 non-null  float32 \n",
      " 53  Fwd Segment Size Avg        103121 non-null  float32 \n",
      " 54  Bwd Segment Size Avg        103121 non-null  float32 \n",
      " 55  Fwd Bytes/Bulk Avg          103121 non-null  int8    \n",
      " 56  Fwd Packet/Bulk Avg         103121 non-null  int8    \n",
      " 57  Fwd Bulk Rate Avg           103121 non-null  int8    \n",
      " 58  Bwd Bytes/Bulk Avg          103121 non-null  int8    \n",
      " 59  Bwd Packet/Bulk Avg         103121 non-null  int32   \n",
      " 60  Bwd Bulk Rate Avg           103121 non-null  int32   \n",
      " 61  Subflow Fwd Packets         103121 non-null  int8    \n",
      " 62  Subflow Fwd Bytes           103121 non-null  int16   \n",
      " 63  Subflow Bwd Packets         103121 non-null  int8    \n",
      " 64  Subflow Bwd Bytes           103121 non-null  int16   \n",
      " 65  FWD Init Win Bytes          103121 non-null  int32   \n",
      " 66  Bwd Init Win Bytes          103121 non-null  int32   \n",
      " 67  Fwd Act Data Packets        103121 non-null  int32   \n",
      " 68  Fwd Seg Size Min            103121 non-null  int8    \n",
      " 69  Active Mean                 103121 non-null  int8    \n",
      " 70  Active Std                  103121 non-null  int8    \n",
      " 71  Active Max                  103121 non-null  int8    \n",
      " 72  Active Min                  103121 non-null  int8    \n",
      " 73  Idle Mean                   103121 non-null  float32 \n",
      " 74  Idle Std                    103121 non-null  float32 \n",
      " 75  Idle Max                    103121 non-null  float32 \n",
      " 76  Idle Min                    103121 non-null  float32 \n",
      " 77  Label                       103121 non-null  category\n",
      " 78  Label.1                     103121 non-null  category\n",
      "dtypes: category(2), float32(22), float64(2), int16(6), int32(25), int8(22)\n",
      "memory usage: 23.6 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Label\n",
       "Non-Tor    64804\n",
       "NonVPN     20216\n",
       "VPN        16922\n",
       "Tor         1179\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"cicdarknet2020.parquet\", engine=\"fastparquet\")\n",
    "df.info()\n",
    "df.head()\n",
    "df['Label'].value_counts()\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c1c1ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INITIAL DATA INSPECTION ===\n",
      "DataFrame shape: (103121, 79)\n",
      "Memory usage: 23.60 MB\n",
      "\n",
      "=== DATA TYPES DETAILED ===\n",
      "Label column info:\n",
      "  dtype: category\n",
      "  type of dtype: <class 'pandas.core.dtypes.dtypes.CategoricalDtype'>\n",
      "  is categorical? True\n",
      "  is string? True\n",
      "\n",
      "Label.1 column info:\n",
      "  dtype: category\n",
      "  type of dtype: <class 'pandas.core.dtypes.dtypes.CategoricalDtype'>\n",
      "  is categorical? True\n",
      "  is string? True\n",
      "\n",
      "=== LABEL VALUES INSPECTION ===\n",
      "First few rows of Label:\n",
      "['Non-Tor', 'Non-Tor', 'Non-Tor', 'Non-Tor', 'Non-Tor', 'Non-Tor', 'Non-Tor', 'Non-Tor', 'Non-Tor', 'Non-Tor']\n",
      "\n",
      "First few rows of Label.1:\n",
      "['AUDIO-STREAMING', 'AUDIO-STREAMING', 'AUDIO-STREAMING', 'AUDIO-STREAMING', 'AUDIO-STREAMING', 'AUDIO-STREAMING', 'AUDIO-STREAMING', 'AUDIO-STREAMING', 'AUDIO-STREAMING', 'AUDIO-STREAMING']\n",
      "\n",
      "=== CHECKING FOR NUMERIC LABELS ===\n",
      "Sample of unique Label values:\n",
      "['Non-Tor', 'NonVPN', 'Tor', 'VPN']\n",
      "\n",
      "Sample of unique Label.1 values:\n",
      "['AUDIO-STREAMING', 'Browsing', 'Chat', 'Email', 'File-Transfer', 'File-transfer', 'P2P', 'Video-Streaming', 'Audio-Streaming', 'Video-streaming', 'VOIP']\n",
      "\n",
      "=== FULL LABEL DISTRIBUTIONS ===\n",
      "Label column value counts (full):\n",
      "Label\n",
      "Non-Tor    64804\n",
      "NonVPN     20216\n",
      "VPN        16922\n",
      "Tor         1179\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label.1 column value counts (full):\n",
      "Label.1\n",
      "Browsing           29862\n",
      "P2P                23404\n",
      "File-Transfer      10564\n",
      "Chat               10365\n",
      "Audio-Streaming     9880\n",
      "Video-Streaming     8742\n",
      "Email               5442\n",
      "VOIP                3061\n",
      "AUDIO-STREAMING     1448\n",
      "Video-streaming      270\n",
      "File-transfer         83\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== INVESTIGATING LABEL MAPPINGS ===\n",
      "Label has 4 unique values\n",
      "Label.1 has 11 unique values\n",
      "\n",
      "Cross-tabulation of Label vs Label.1:\n",
      "Label.1  AUDIO-STREAMING  Audio-Streaming  Browsing  Chat  Email  \\\n",
      "Label                                                              \n",
      "Non-Tor             1448                0     29599   409    474   \n",
      "NonVPN                 0             2417         0  5510   4446   \n",
      "Tor                    0              121       263    65     13   \n",
      "VPN                    0             7342         0  4381    509   \n",
      "\n",
      "Label.1  File-Transfer  File-transfer    P2P  VOIP  Video-Streaming  \\\n",
      "Label                                                                 \n",
      "Non-Tor           6230             46  23294     0             3304   \n",
      "NonVPN            1733             37      0  1690             4113   \n",
      "Tor                107              0    110   298              202   \n",
      "VPN               2494              0      0  1073             1123   \n",
      "\n",
      "Label.1  Video-streaming  \n",
      "Label                     \n",
      "Non-Tor                0  \n",
      "NonVPN               270  \n",
      "Tor                    0  \n",
      "VPN                    0  \n",
      "\n",
      "=== DECIDING WHICH LABEL TO USE ===\n",
      "Based on your output:\n",
      "1. Label column: Has values 0, 1, 2, 3 (4 classes)\n",
      "2. Label.1 column: Has actual names like 'Browsing', 'P2P', etc.\n",
      "\n",
      "Checking if Label is already encoded...\n",
      "Label: Non-Tor -> Label.1: P2P\n",
      "Label: Non-Tor -> Label.1: Browsing\n",
      "Label: VPN -> Label.1: Audio-Streaming\n",
      "Label: Non-Tor -> Label.1: Browsing\n",
      "Label: VPN -> Label.1: Chat\n",
      "Label: NonVPN -> Label.1: Chat\n",
      "Label: NonVPN -> Label.1: Audio-Streaming\n",
      "Label: Non-Tor -> Label.1: Browsing\n",
      "Label: Non-Tor -> Label.1: P2P\n",
      "Label: Tor -> Label.1: VOIP\n",
      "Label: Non-Tor -> Label.1: Browsing\n",
      "Label: VPN -> Label.1: Chat\n",
      "Label: Non-Tor -> Label.1: P2P\n",
      "Label: Non-Tor -> Label.1: Browsing\n",
      "Label: NonVPN -> Label.1: File-Transfer\n",
      "Label: NonVPN -> Label.1: Email\n",
      "Label: Non-Tor -> Label.1: Browsing\n",
      "Label: Non-Tor -> Label.1: Email\n",
      "Label: VPN -> Label.1: VOIP\n",
      "Label: Non-Tor -> Label.1: Video-Streaming\n",
      "Label: Non-Tor -> Label.1: Browsing\n",
      "Label: Non-Tor -> Label.1: File-Transfer\n",
      "Label: NonVPN -> Label.1: Audio-Streaming\n",
      "Label: NonVPN -> Label.1: Audio-Streaming\n",
      "Label: Non-Tor -> Label.1: Browsing\n",
      "Label: Non-Tor -> Label.1: P2P\n",
      "Label: Non-Tor -> Label.1: P2P\n",
      "Label: VPN -> Label.1: VOIP\n",
      "Label: Non-Tor -> Label.1: Browsing\n",
      "Label: Non-Tor -> Label.1: P2P\n",
      "Label: Non-Tor -> Label.1: P2P\n",
      "Label: Non-Tor -> Label.1: Browsing\n",
      "Label: VPN -> Label.1: Audio-Streaming\n",
      "Label: VPN -> Label.1: File-Transfer\n",
      "Label: NonVPN -> Label.1: Video-Streaming\n",
      "Label: Non-Tor -> Label.1: Browsing\n",
      "Label: VPN -> Label.1: Video-Streaming\n",
      "Label: Non-Tor -> Label.1: Browsing\n",
      "Label: Non-Tor -> Label.1: P2P\n",
      "Label: VPN -> Label.1: Chat\n",
      "Label: NonVPN -> Label.1: Chat\n",
      "Label: Non-Tor -> Label.1: Browsing\n",
      "Label: Non-Tor -> Label.1: P2P\n",
      "Label: Non-Tor -> Label.1: Browsing\n",
      "Label: Non-Tor -> Label.1: Browsing\n",
      "Label: Non-Tor -> Label.1: Browsing\n",
      "Label: VPN -> Label.1: Email\n",
      "Label: NonVPN -> Label.1: Chat\n",
      "Label: NonVPN -> Label.1: Audio-Streaming\n",
      "Label: Non-Tor -> Label.1: Browsing\n",
      "Label: VPN -> Label.1: File-Transfer\n",
      "Label: Non-Tor -> Label.1: Browsing\n",
      "Label: Non-Tor -> Label.1: File-Transfer\n",
      "Label: VPN -> Label.1: Audio-Streaming\n",
      "Label: VPN -> Label.1: File-Transfer\n",
      "Label: NonVPN -> Label.1: Email\n",
      "Label: VPN -> Label.1: Chat\n",
      "Label: Non-Tor -> Label.1: P2P\n",
      "Label: NonVPN -> Label.1: Email\n",
      "Label: Non-Tor -> Label.1: P2P\n",
      "Label: Non-Tor -> Label.1: Browsing\n",
      "Label: NonVPN -> Label.1: Email\n",
      "Label: Non-Tor -> Label.1: Browsing\n",
      "Label: Non-Tor -> Label.1: Browsing\n",
      "Label: Non-Tor -> Label.1: P2P\n",
      "Label: Non-Tor -> Label.1: Browsing\n",
      "Label: Non-Tor -> Label.1: P2P\n",
      "Label: Non-Tor -> Label.1: Browsing\n",
      "Label: Non-Tor -> Label.1: P2P\n",
      "Label: VPN -> Label.1: Chat\n",
      "Label: Non-Tor -> Label.1: P2P\n",
      "Label: VPN -> Label.1: Audio-Streaming\n",
      "Label: NonVPN -> Label.1: Audio-Streaming\n",
      "Label: Non-Tor -> Label.1: P2P\n",
      "Label: VPN -> Label.1: Chat\n",
      "Label: Non-Tor -> Label.1: AUDIO-STREAMING\n",
      "Label: VPN -> Label.1: Chat\n",
      "Label: VPN -> Label.1: Chat\n",
      "Label: Non-Tor -> Label.1: Browsing\n",
      "Label: Non-Tor -> Label.1: Browsing\n",
      "Label: NonVPN -> Label.1: Video-Streaming\n",
      "Label: Non-Tor -> Label.1: P2P\n",
      "Label: NonVPN -> Label.1: Audio-Streaming\n",
      "Label: VPN -> Label.1: Audio-Streaming\n",
      "Label: Non-Tor -> Label.1: File-Transfer\n",
      "Label: Non-Tor -> Label.1: P2P\n",
      "Label: NonVPN -> Label.1: File-transfer\n",
      "Label: Non-Tor -> Label.1: Browsing\n",
      "Label: NonVPN -> Label.1: Video-Streaming\n",
      "Label: NonVPN -> Label.1: File-Transfer\n",
      "Label: VPN -> Label.1: File-Transfer\n",
      "Label: NonVPN -> Label.1: Audio-Streaming\n",
      "Label: VPN -> Label.1: Audio-Streaming\n",
      "Label: Non-Tor -> Label.1: File-Transfer\n",
      "Label: Non-Tor -> Label.1: P2P\n",
      "Label: Non-Tor -> Label.1: Browsing\n",
      "Label: Non-Tor -> Label.1: AUDIO-STREAMING\n",
      "Label: Non-Tor -> Label.1: File-Transfer\n",
      "Label: Non-Tor -> Label.1: Browsing\n",
      "Label: VPN -> Label.1: Video-Streaming\n",
      "\n",
      "=== CREATING PROPER LABEL MAPPING ===\n",
      "             most_common  num_unique  \\\n",
      "Label                                  \n",
      "Non-Tor  AUDIO-STREAMING           8   \n",
      "NonVPN              Chat           8   \n",
      "Tor      Audio-Streaming           8   \n",
      "VPN        File-Transfer           6   \n",
      "\n",
      "                                             sample_values  \n",
      "Label                                                       \n",
      "Non-Tor  [AUDIO-STREAMING, Browsing, Chat, Email, File-...  \n",
      "NonVPN   [Chat, Audio-Streaming, Email, File-Transfer, ...  \n",
      "Tor      [Audio-Streaming, Browsing, Chat, File-Transfe...  \n",
      "VPN      [File-Transfer, Chat, Audio-Streaming, Email, ...  \n",
      "\n",
      "Based on analysis, I recommend using Label.1 as it has the actual class names\n",
      "\n",
      "=== DATA CLEANING ===\n",
      "Checking for duplicate columns...\n",
      "Duplicate columns: []\n",
      "Constant columns: ['Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Fwd Bytes/Bulk Avg', 'Fwd Packet/Bulk Avg', 'Fwd Bulk Rate Avg', 'Bwd Bytes/Bulk Avg', 'Subflow Bwd Packets', 'Active Mean', 'Active Std', 'Active Max', 'Active Min']\n",
      "Dropped constant columns: ['Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Fwd Bytes/Bulk Avg', 'Fwd Packet/Bulk Avg', 'Fwd Bulk Rate Avg', 'Bwd Bytes/Bulk Avg', 'Subflow Bwd Packets', 'Active Mean', 'Active Std', 'Active Max', 'Active Min']\n",
      "\n",
      "=== HANDLING MISSING/INFINITE VALUES ===\n",
      "\n",
      "=== LABEL PROCESSING ===\n",
      "\n",
      "Cleaned label distribution:\n",
      "  'browsing': 29862 samples (28.96%)\n",
      "  'p2p': 23404 samples (22.70%)\n",
      "  'audio-streaming': 11328 samples (10.99%)\n",
      "  'file-transfer': 10647 samples (10.32%)\n",
      "  'chat': 10365 samples (10.05%)\n",
      "  'video-streaming': 9012 samples (8.74%)\n",
      "  'email': 5442 samples (5.28%)\n",
      "  'voip': 3061 samples (2.97%)\n",
      "\n",
      "=== FINAL LABEL ENCODING ===\n",
      "Class mapping:\n",
      "  0: 'audio-streaming' - 11328 samples (10.99%)\n",
      "  1: 'browsing' - 29862 samples (28.96%)\n",
      "  2: 'chat' - 10365 samples (10.05%)\n",
      "  3: 'email' - 5442 samples (5.28%)\n",
      "  4: 'file-transfer' - 10647 samples (10.32%)\n",
      "  5: 'p2p' - 23404 samples (22.70%)\n",
      "  6: 'video-streaming' - 9012 samples (8.74%)\n",
      "  7: 'voip' - 3061 samples (2.97%)\n",
      "\n",
      "=== FEATURE PREPARATION ===\n",
      "Features shape: (103121, 62)\n",
      "Labels shape: (103121,)\n",
      "\n",
      "=== FEATURE SCALING ===\n",
      "Scaled 62 numeric features\n",
      "\n",
      "=== DATA SPLITTING ===\n",
      "Class distribution:\n",
      "  1: 'browsing' - 29862 samples (28.96%)\n",
      "  5: 'p2p' - 23404 samples (22.70%)\n",
      "  0: 'audio-streaming' - 11328 samples (10.99%)\n",
      "  4: 'file-transfer' - 10647 samples (10.32%)\n",
      "  2: 'chat' - 10365 samples (10.05%)\n",
      "  6: 'video-streaming' - 9012 samples (8.74%)\n",
      "  3: 'email' - 5442 samples (5.28%)\n",
      "  7: 'voip' - 3061 samples (2.97%)\n",
      "\n",
      "Using stratified split\n",
      "\n",
      "Training set: 82496 samples\n",
      "Testing set: 20625 samples\n",
      "\n",
      "=== SAVING DATA ===\n",
      "Saved to: cicdarknet_preprocessed_20251209_174537.pkl\n",
      "\n",
      "=== SUMMARY ===\n",
      "Original data: (103121, 67)\n",
      "Features: 62\n",
      "Classes: 8\n",
      "Training samples: 82496\n",
      "Test samples: 20625\n",
      "\n",
      "Saving sample for inspection...\n",
      "Sample saved to 'preprocessed_sample.csv'\n",
      "\n",
      "=== PREPROCESSING SUMMARY ===\n",
      "Original dataset shape: (103121, 67)\n",
      "Number of classes: 8\n",
      "Feature matrix shape: (103121, 62)\n",
      "Training samples: 82496\n",
      "Testing samples: 20625\n",
      "Number of features: 62\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_parquet(\"cicdarknet2020.parquet\", engine=\"fastparquet\")\n",
    "\n",
    "print(\"=== INITIAL DATA INSPECTION ===\")\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "print(f\"Memory usage: {df.memory_usage().sum() / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# Let's check the actual dtypes more carefully\n",
    "print(\"\\n=== DATA TYPES DETAILED ===\")\n",
    "print(\"Label column info:\")\n",
    "print(f\"  dtype: {df['Label'].dtype}\")\n",
    "print(f\"  type of dtype: {type(df['Label'].dtype)}\")\n",
    "print(f\"  is categorical? {pd.api.types.is_categorical_dtype(df['Label'])}\")\n",
    "print(f\"  is string? {pd.api.types.is_string_dtype(df['Label'])}\")\n",
    "\n",
    "print(\"\\nLabel.1 column info:\")\n",
    "print(f\"  dtype: {df['Label.1'].dtype}\")\n",
    "print(f\"  type of dtype: {type(df['Label.1'].dtype)}\")\n",
    "print(f\"  is categorical? {pd.api.types.is_categorical_dtype(df['Label.1'])}\")\n",
    "print(f\"  is string? {pd.api.types.is_string_dtype(df['Label.1'])}\")\n",
    "\n",
    "# Let's see what values are actually in these columns\n",
    "print(\"\\n=== LABEL VALUES INSPECTION ===\")\n",
    "print(\"First few rows of Label:\")\n",
    "print(df['Label'].head(10).tolist())\n",
    "print(\"\\nFirst few rows of Label.1:\")\n",
    "print(df['Label.1'].head(10).tolist())\n",
    "\n",
    "# Check if they might be numeric codes disguised as strings\n",
    "print(\"\\n=== CHECKING FOR NUMERIC LABELS ===\")\n",
    "print(\"Sample of unique Label values:\")\n",
    "print(df['Label'].drop_duplicates().head(20).tolist())\n",
    "\n",
    "print(\"\\nSample of unique Label.1 values:\")\n",
    "print(df['Label.1'].drop_duplicates().head(20).tolist())\n",
    "\n",
    "# Let's see the actual value counts you mentioned\n",
    "print(\"\\n=== FULL LABEL DISTRIBUTIONS ===\")\n",
    "print(\"Label column value counts (full):\")\n",
    "print(df['Label'].value_counts())\n",
    "\n",
    "print(\"\\nLabel.1 column value counts (full):\")\n",
    "print(df['Label.1'].value_counts())\n",
    "\n",
    "# Based on your output, it seems Label might be numeric codes\n",
    "# Let's investigate the mappings\n",
    "print(\"\\n=== INVESTIGATING LABEL MAPPINGS ===\")\n",
    "print(f\"Label has {df['Label'].nunique()} unique values\")\n",
    "print(f\"Label.1 has {df['Label.1'].nunique()} unique values\")\n",
    "\n",
    "# Create a cross-tab to see the relationship\n",
    "if df['Label'].nunique() < 20 and df['Label.1'].nunique() < 20:\n",
    "    print(\"\\nCross-tabulation of Label vs Label.1:\")\n",
    "    print(pd.crosstab(df['Label'], df['Label.1']))\n",
    "else:\n",
    "    print(\"\\nToo many unique values for cross-tab (showing sample)\")\n",
    "    sample_df = df[['Label', 'Label.1']].sample(min(1000, len(df)))\n",
    "    print(pd.crosstab(sample_df['Label'], sample_df['Label.1']))\n",
    "\n",
    "# DECISION TIME: Which label to use?\n",
    "print(\"\\n=== DECIDING WHICH LABEL TO USE ===\")\n",
    "print(\"Based on your output:\")\n",
    "print(\"1. Label column: Has values 0, 1, 2, 3 (4 classes)\")\n",
    "print(\"2. Label.1 column: Has actual names like 'Browsing', 'P2P', etc.\")\n",
    "\n",
    "# Let me check if Label might be encoded already\n",
    "print(\"\\nChecking if Label is already encoded...\")\n",
    "# Get a mapping by sampling\n",
    "sample_size = min(100, len(df))\n",
    "sample = df[['Label', 'Label.1']].sample(sample_size)\n",
    "for _, row in sample.iterrows():\n",
    "    print(f\"Label: {row['Label']} -> Label.1: {row['Label.1']}\")\n",
    "\n",
    "# Based on what you showed, it looks like:\n",
    "# Label: 0, 1, 2, 3 (encoded classes)\n",
    "# Label.1: Actual class names\n",
    "\n",
    "# Let's create a proper mapping\n",
    "print(\"\\n=== CREATING PROPER LABEL MAPPING ===\")\n",
    "# Group by Label and see what Label.1 values correspond\n",
    "label_mapping_df = df.groupby('Label')['Label.1'].agg(['first', 'nunique', lambda x: list(x.unique())[:5]])\n",
    "label_mapping_df.columns = ['most_common', 'num_unique', 'sample_values']\n",
    "print(label_mapping_df)\n",
    "\n",
    "# If Label is already encoded and Label.1 has the names, use Label.1\n",
    "print(\"\\nBased on analysis, I recommend using Label.1 as it has the actual class names\")\n",
    "\n",
    "# Clean up the data\n",
    "print(\"\\n=== DATA CLEANING ===\")\n",
    "print(\"Checking for duplicate columns...\")\n",
    "duplicate_columns = df.columns[df.columns.duplicated()]\n",
    "print(f\"Duplicate columns: {list(duplicate_columns)}\")\n",
    "\n",
    "# Check for constant columns\n",
    "constant_columns = [col for col in df.columns if df[col].nunique() == 1]\n",
    "print(f\"Constant columns: {constant_columns}\")\n",
    "\n",
    "if constant_columns:\n",
    "    df = df.drop(columns=constant_columns)\n",
    "    print(f\"Dropped constant columns: {constant_columns}\")\n",
    "\n",
    "# Handle missing/infinite values\n",
    "print(\"\\n=== HANDLING MISSING/INFINITE VALUES ===\")\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "for col in numeric_cols:\n",
    "    df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "nan_counts = df.isnull().sum()\n",
    "if nan_counts.any():\n",
    "    nan_cols = nan_counts[nan_counts > 0].index.tolist()\n",
    "    print(f\"Columns with NaN: {nan_cols}\")\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if df[col].isnull().any():\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "# Now process the labels\n",
    "print(\"\\n=== LABEL PROCESSING ===\")\n",
    "# Use Label.1 since it has the actual names\n",
    "df['Label_original'] = df['Label.1'].astype(str)\n",
    "\n",
    "# Clean the labels\n",
    "df['Label_cleaned'] = df['Label_original'].str.lower().str.strip()\n",
    "\n",
    "# Check cleaned labels\n",
    "print(\"\\nCleaned label distribution:\")\n",
    "cleaned_counts = df['Label_cleaned'].value_counts()\n",
    "for label, count in cleaned_counts.items():\n",
    "    proportion = count / len(df) * 100\n",
    "    print(f\"  '{label}': {count} samples ({proportion:.2f}%)\")\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['Label_encoded'] = label_encoder.fit_transform(df['Label_cleaned'])\n",
    "\n",
    "print(\"\\n=== FINAL LABEL ENCODING ===\")\n",
    "print(\"Class mapping:\")\n",
    "for i, label in enumerate(label_encoder.classes_):\n",
    "    count = (df['Label_cleaned'] == label).sum()\n",
    "    proportion = count / len(df) * 100\n",
    "    print(f\"  {i}: '{label}' - {count} samples ({proportion:.2f}%)\")\n",
    "\n",
    "label_mapping = dict(zip(range(len(label_encoder.classes_)), label_encoder.classes_))\n",
    "\n",
    "# Prepare features\n",
    "print(\"\\n=== FEATURE PREPARATION ===\")\n",
    "# Exclude all label-related columns\n",
    "label_cols = ['Label', 'Label.1', 'Label_original', 'Label_cleaned', 'Label_encoded']\n",
    "exclude_cols = [col for col in label_cols if col in df.columns]\n",
    "\n",
    "feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df['Label_encoded']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Labels shape: {y.shape}\")\n",
    "\n",
    "# Scale features\n",
    "print(\"\\n=== FEATURE SCALING ===\")\n",
    "scaler = StandardScaler()\n",
    "X_scaled = X.copy()\n",
    "numeric_features = X.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "if len(numeric_features) > 0:\n",
    "    X_scaled[numeric_features] = scaler.fit_transform(X[numeric_features])\n",
    "    print(f\"Scaled {len(numeric_features)} numeric features\")\n",
    "else:\n",
    "    print(\"No numeric features to scale\")\n",
    "\n",
    "# Split data\n",
    "print(\"\\n=== DATA SPLITTING ===\")\n",
    "class_counts = y.value_counts()\n",
    "print(\"Class distribution:\")\n",
    "for class_id, count in class_counts.items():\n",
    "    class_name = label_encoder.inverse_transform([class_id])[0]\n",
    "    proportion = count / len(y) * 100\n",
    "    print(f\"  {class_id}: '{class_name}' - {count} samples ({proportion:.2f}%)\")\n",
    "\n",
    "# Use stratification if possible\n",
    "if class_counts.min() >= 2:\n",
    "    print(\"\\nUsing stratified split\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "else:\n",
    "    print(\"\\nUsing random split (some classes have < 2 samples)\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Save processed data\n",
    "print(\"\\n=== SAVING DATA ===\")\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "preprocessed_data = {\n",
    "    'X_train': X_train,\n",
    "    'X_test': X_test,\n",
    "    'y_train': y_train,\n",
    "    'y_test': y_test,\n",
    "    'scaler': scaler,\n",
    "    'label_encoder': label_encoder,\n",
    "    'feature_names': X_train.columns.tolist(),\n",
    "    'label_mapping': label_mapping,\n",
    "    'num_classes': len(label_encoder.classes_)\n",
    "}\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = f'cicdarknet_preprocessed_{timestamp}.pkl'\n",
    "\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(preprocessed_data, f)\n",
    "\n",
    "print(f\"Saved to: {filename}\")\n",
    "print(\"\\n=== SUMMARY ===\")\n",
    "print(f\"Original data: {df.shape}\")\n",
    "print(f\"Features: {X_train.shape[1]}\")\n",
    "print(f\"Classes: {len(label_encoder.classes_)}\")\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Test samples: {X_test.shape[0]}\")\n",
    "\n",
    "# Also save a CSV for inspection\n",
    "print(\"\\nSaving sample for inspection...\")\n",
    "sample_data = pd.DataFrame(X_train.iloc[:100])\n",
    "sample_data['label'] = y_train.iloc[:100].values\n",
    "sample_data['label_name'] = label_encoder.inverse_transform(y_train.iloc[:100])\n",
    "sample_data.to_csv('preprocessed_sample.csv', index=False)\n",
    "print(\"Sample saved to 'preprocessed_sample.csv'\")\n",
    "\n",
    "# Quick summary\n",
    "print(\"\\n=== PREPROCESSING SUMMARY ===\")\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(f\"Number of classes: {len(label_encoder.classes_)}\")\n",
    "print(f\"Feature matrix shape: {X_scaled.shape}\")\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Testing samples: {X_test.shape[0]}\")\n",
    "print(f\"Number of features: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091c982f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
